{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ea070b-ac47-41ea-903f-0790f47cbc25",
   "metadata": {},
   "source": [
    "**Projet 8: Traiter les images pour le système embarqué d’une voiture autonome** \n",
    "\n",
    "Dans ce notebook, nous allons tester différents modèles pour réaliser une segmentation en 8 catégories des images pour le système embarqué d'une voiture autonome;\n",
    "Nous commencerons par des modèles \"basiques\", qui seront notre baseline de référence vs des modeles plus élaborés de deep learning.\n",
    "Dans l'orde nous allons tester:\n",
    "* \n",
    "\n",
    "Tous les modeles sont stockés en centralisé sur MLflow (local).\n",
    "Le modèle le plus performant (avec la meilleure accuracy) sera utilisé pour le déploiement en production sur le cloud via un API de prediction.\n",
    "Derriere, nous developperons également un pipeline CI/CD qui nous aidera à déployer le dernier modele automatiquement sur le cloud sur simple PUSH via Git Hub Actions;\n",
    "\n",
    "> \"View\" > \"Table of contents\" pour voir le plan du notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b3cee1-d82b-4460-b922-d790cd10d398",
   "metadata": {},
   "source": [
    "# 1. Imports et paramétrages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b908c6e-d19a-47d8-a684-6a92760df573",
   "metadata": {},
   "source": [
    "## 1.1 Installation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1455d9e-f4ab-4614-b81c-973e4607734c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: missingno in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: mlflow in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (2.20.3)\n",
      "Requirement already satisfied: tf-keras in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: albumentations in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (2.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from missingno) (0.13.2)\n",
      "Requirement already satisfied: mlflow-skinny==2.20.3 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow) (2.20.3)\n",
      "Requirement already satisfied: Flask<4 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow) (3.1.0)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow) (3.1.5)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow) (1.14.1)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: pyarrow<20,>=4.0.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow) (19.0.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow) (2.0.38)\n",
      "Requirement already satisfied: waitress<4 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle<4 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow) (0.44.1)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow) (3.1.44)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow) (1.30.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow) (5.29.3)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow) (2.10.6)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow) (2.32.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow) (4.12.2)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: albucore==0.0.23 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from albumentations) (0.0.23)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from albumentations) (4.11.0.86)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from albucore==0.0.23->albumentations) (3.12.2)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from albucore==0.0.23->albumentations) (6.2.1)\n",
      "Requirement already satisfied: Mako in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.9)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (308)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from graphene<4->mlflow) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (3.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.3->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.3->mlflow) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (75.8.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: google-auth~=2.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (2.38.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.20.3->mlflow) (4.0.12)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.20.3->mlflow) (3.21.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (1.2.18)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (0.51b0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.3->mlflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.3->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.3->mlflow) (2025.1.31)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.20.3->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (4.9)\n",
      "Requirement already satisfied: rich in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.14.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (0.6.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\flore\\openclassrooms\\projet 8\\envp8\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib scikit-learn missingno mlflow tf-keras tqdm albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba664684-3037-4742-abf1-18234065b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas numpy seaborn matplotlib scikit-learn missingno nltk \n",
    "# !pip install gensim transformers tensorflow-cpu==2.16.1 tf-keras==2.16.0 tensorflow_hub plot-keras-history\n",
    "# !pip install opencv-python-headless opencv-contrib-python "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b1aa1b-4688-425a-b8cc-7883a7b83071",
   "metadata": {},
   "source": [
    "## 1.2 Import des Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2434c57b-acf9-4daa-994f-c127cbba7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9da40780-2675-4ce9-9b5f-a6e2e3859921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==2.1.0\n",
      "albucore==0.0.23\n",
      "albumentations==2.0.5\n",
      "alembic==1.14.1\n",
      "annotated-types==0.7.0\n",
      "anyio==4.8.0\n",
      "argon2-cffi==23.1.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "arrow==1.3.0\n",
      "asttokens==3.0.0\n",
      "astunparse==1.6.3\n",
      "async-lru==2.0.4\n",
      "attrs==25.1.0\n",
      "babel==2.17.0\n",
      "beautifulsoup4==4.13.3\n",
      "bleach==6.2.0\n",
      "blinker==1.9.0\n",
      "cachetools==5.5.2\n",
      "certifi==2025.1.31\n",
      "cffi==1.17.1\n",
      "charset-normalizer==3.4.1\n",
      "click==8.1.8\n",
      "cloudpickle==3.1.1\n",
      "colorama==0.4.6\n",
      "comm==0.2.2\n",
      "contourpy==1.3.1\n",
      "cycler==0.12.1\n",
      "databricks-sdk==0.44.1\n",
      "debugpy==1.8.12\n",
      "decorator==5.2.1\n",
      "defusedxml==0.7.1\n",
      "Deprecated==1.2.18\n",
      "docker==7.1.0\n",
      "executing==2.2.0\n",
      "fastjsonschema==2.21.1\n",
      "Flask==3.1.0\n",
      "flatbuffers==25.2.10\n",
      "fonttools==4.56.0\n",
      "fqdn==1.5.1\n",
      "gast==0.6.0\n",
      "gitdb==4.0.12\n",
      "GitPython==3.1.44\n",
      "google-auth==2.38.0\n",
      "google-pasta==0.2.0\n",
      "graphene==3.4.3\n",
      "graphql-core==3.2.6\n",
      "graphql-relay==3.2.0\n",
      "greenlet==3.1.1\n",
      "grpcio==1.70.0\n",
      "h11==0.14.0\n",
      "h5py==3.13.0\n",
      "httpcore==1.0.7\n",
      "httpx==0.28.1\n",
      "idna==3.10\n",
      "importlib_metadata==8.5.0\n",
      "ipykernel==6.29.5\n",
      "ipython==9.0.0\n",
      "ipython_pygments_lexers==1.1.1\n",
      "ipywidgets==8.1.5\n",
      "isoduration==20.11.0\n",
      "itsdangerous==2.2.0\n",
      "jedi==0.19.2\n",
      "Jinja2==3.1.5\n",
      "joblib==1.4.2\n",
      "json5==0.10.0\n",
      "jsonpointer==3.0.0\n",
      "jsonschema==4.23.0\n",
      "jsonschema-specifications==2024.10.1\n",
      "jupyter==1.1.1\n",
      "jupyter-console==6.6.3\n",
      "jupyter-events==0.12.0\n",
      "jupyter-lsp==2.2.5\n",
      "jupyter_client==8.6.3\n",
      "jupyter_core==5.7.2\n",
      "jupyter_server==2.15.0\n",
      "jupyter_server_terminals==0.5.3\n",
      "jupyterlab==4.3.5\n",
      "jupyterlab_pygments==0.3.0\n",
      "jupyterlab_server==2.27.3\n",
      "jupyterlab_widgets==3.0.13\n",
      "keras==3.8.0\n",
      "kiwisolver==1.4.8\n",
      "libclang==18.1.1\n",
      "Mako==1.3.9\n",
      "Markdown==3.7\n",
      "markdown-it-py==3.0.0\n",
      "MarkupSafe==3.0.2\n",
      "matplotlib==3.10.1\n",
      "matplotlib-inline==0.1.7\n",
      "mdurl==0.1.2\n",
      "missingno==0.5.2\n",
      "mistune==3.1.2\n",
      "ml-dtypes==0.4.1\n",
      "mlflow==2.20.3\n",
      "mlflow-skinny==2.20.3\n",
      "namex==0.0.8\n",
      "nbclient==0.10.2\n",
      "nbconvert==7.16.6\n",
      "nbformat==5.10.4\n",
      "nest-asyncio==1.6.0\n",
      "notebook==7.3.2\n",
      "notebook_shim==0.2.4\n",
      "numpy==2.0.2\n",
      "opencv-python-headless==4.11.0.86\n",
      "opentelemetry-api==1.30.0\n",
      "opentelemetry-sdk==1.30.0\n",
      "opentelemetry-semantic-conventions==0.51b0\n",
      "opt_einsum==3.4.0\n",
      "optree==0.14.1\n",
      "overrides==7.7.0\n",
      "packaging==24.2\n",
      "pandas==2.2.3\n",
      "pandocfilters==1.5.1\n",
      "parso==0.8.4\n",
      "pillow==11.1.0\n",
      "platformdirs==4.3.6\n",
      "prometheus_client==0.21.1\n",
      "prompt_toolkit==3.0.50\n",
      "protobuf==5.29.3\n",
      "psutil==7.0.0\n",
      "pure_eval==0.2.3\n",
      "pyarrow==19.0.1\n",
      "pyasn1==0.6.1\n",
      "pyasn1_modules==0.4.1\n",
      "pycparser==2.22\n",
      "pydantic==2.10.6\n",
      "pydantic_core==2.27.2\n",
      "Pygments==2.19.1\n",
      "pyparsing==3.2.1\n",
      "python-dateutil==2.9.0.post0\n",
      "python-json-logger==3.2.1\n",
      "pytz==2025.1\n",
      "pywin32==308\n",
      "pywinpty==2.0.15\n",
      "PyYAML==6.0.2\n",
      "pyzmq==26.2.1\n",
      "referencing==0.36.2\n",
      "requests==2.32.3\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986-validator==0.1.1\n",
      "rich==13.9.4\n",
      "rpds-py==0.23.1\n",
      "rsa==4.9\n",
      "scikit-learn==1.6.1\n",
      "scipy==1.15.2\n",
      "seaborn==0.13.2\n",
      "Send2Trash==1.8.3\n",
      "setuptools==75.8.2\n",
      "simsimd==6.2.1\n",
      "six==1.17.0\n",
      "smmap==5.0.2\n",
      "sniffio==1.3.1\n",
      "soupsieve==2.6\n",
      "SQLAlchemy==2.0.38\n",
      "sqlparse==0.5.3\n",
      "stack-data==0.6.3\n",
      "stringzilla==3.12.2\n",
      "tensorboard==2.18.0\n",
      "tensorboard-data-server==0.7.2\n",
      "tensorflow==2.18.0\n",
      "tensorflow_intel==2.18.0\n",
      "termcolor==2.5.0\n",
      "terminado==0.18.1\n",
      "tf_keras==2.18.0\n",
      "threadpoolctl==3.5.0\n",
      "tinycss2==1.4.0\n",
      "tornado==6.4.2\n",
      "tqdm==4.67.1\n",
      "traitlets==5.14.3\n",
      "types-python-dateutil==2.9.0.20241206\n",
      "typing_extensions==4.12.2\n",
      "tzdata==2025.1\n",
      "uri-template==1.3.0\n",
      "urllib3==2.3.0\n",
      "waitress==3.0.2\n",
      "wcwidth==0.2.13\n",
      "webcolors==24.11.1\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.8.0\n",
      "Werkzeug==3.1.3\n",
      "wheel==0.45.1\n",
      "widgetsnbextension==4.0.13\n",
      "wrapt==1.17.2\n",
      "zipp==3.21.0\n"
     ]
    }
   ],
   "source": [
    "! pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd579b9-b8b1-4057-b7d6-2a393ded6101",
   "metadata": {},
   "source": [
    "## 1.3 Paramétrages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f2c3559-e90f-46d8-b516-9c44b0aa10bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#parametrage de panda pour afficher toutes les colonnes sans les tronquer\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mpd\u001b[49m.set_option(\u001b[33m'\u001b[39m\u001b[33mdisplay.max_columns\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m      3\u001b[39m pd.set_option(\u001b[33m'\u001b[39m\u001b[33mdisplay.max_rows\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Application des paramètres de style par défaut de Seaborn\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#parametrage de panda pour afficher toutes les colonnes sans les tronquer\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Application des paramètres de style par défaut de Seaborn\n",
    "sns.set()\n",
    "\n",
    "# disable WARNING, INFO and DEBUG logging everywhere\n",
    "# logging.disable(logging.WARNING) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d3dde-44f3-42b1-b75d-b9b6ae54f885",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Configuration MLflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"analyse_sentiment_tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663755ed-d113-4fe5-bc2a-f8ef36a74450",
   "metadata": {},
   "source": [
    "## 1.4 Fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38a3035-738d-46db-bf09-1b918809d920",
   "metadata": {},
   "source": [
    "### 1.4.1 Obtention des chemins pour images et masques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62219a43-5a60-4ec9-b130-60c5db19fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extensions valides pour les images\n",
    "IMAGE_EXTENSIONS = {\".png\", \".jpg\", \".jpeg\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aaffdc-f6cd-4d86-83bb-d132bb5990f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_image_paths(root_dir):\n",
    "    \"\"\"\n",
    "    Récupère les chemins des images en parcourant récursivement les dossiers.\n",
    "    Trie les chemins en fonction de leur emplacement relatif pour assurer l'alignement entre images et masques.\n",
    "    Ignore les images du dossier 'test/' car leurs masques relatifs ne sont pas fournis par Cityscape.\n",
    "    \"\"\"\n",
    "    paths = [\n",
    "        p for p in Path(root_dir).rglob(\"*\") \n",
    "        if p.suffix.lower() in IMAGE_EXTENSIONS\n",
    "        and (\"train\" in str(p) or \"val\" in str(p))  # Ignore \"test/\"\n",
    "    ]\n",
    "    return sorted(paths, key=lambda p: p.relative_to(root_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb150b-915a-4e05-b527-a2eac23b8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_paths(root_dir, mask_type=\"_gtFine_labelIds\"):\n",
    "    \"\"\"\n",
    "    Récupère les chemins des masques en filtrant ceux contenant un type spécifique.\n",
    "    Utilise les masques de segmentation sémantique (_gtFine_labelIds).\n",
    "    Ignore les masques du dossier 'test/' car ils ne sont pas fournis.\n",
    "    \"\"\"\n",
    "    paths = [\n",
    "        p for p in Path(root_dir).rglob(\"*\")\n",
    "        if p.suffix.lower() in IMAGE_EXTENSIONS \n",
    "        and mask_type in p.stem \n",
    "        and (\"train\" in str(p) or \"val\" in str(p))  # Ignore \"test/\"\n",
    "    ]\n",
    "    return sorted(paths, key=lambda p: p.relative_to(root_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c6a3f6-2373-4b09-b6d8-2dcb925a1573",
   "metadata": {},
   "source": [
    "### 1.4.2 Simplification des catégories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a15771-a404-407b-9ed7-3bc386229699",
   "metadata": {},
   "source": [
    "code pour visualiser les différentes categs de cityscapes. \n",
    "Ce code provient directement du github de cityscapes: \n",
    "https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/helpers/labels.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23407e55-00b0-46dc-938c-c05acfbffa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117f167a-626b-45fc-abce-d632ff9807af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Definitions\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# a label and all meta information\n",
    "Label = namedtuple( 'Label' , [\n",
    "\n",
    "    'name'        , # The identifier of this label, e.g. 'car', 'person', ... .\n",
    "                    # We use them to uniquely name a class\n",
    "\n",
    "    'id'          , # An integer ID that is associated with this label.\n",
    "                    # The IDs are used to represent the label in ground truth images\n",
    "                    # An ID of -1 means that this label does not have an ID and thus\n",
    "                    # is ignored when creating ground truth images (e.g. license plate).\n",
    "                    # Do not modify these IDs, since exactly these IDs are expected by the\n",
    "                    # evaluation server.\n",
    "\n",
    "    'trainId'     , # Feel free to modify these IDs as suitable for your method. Then create\n",
    "                    # ground truth images with train IDs, using the tools provided in the\n",
    "                    # 'preparation' folder. However, make sure to validate or submit results\n",
    "                    # to our evaluation server using the regular IDs above!\n",
    "                    # For trainIds, multiple labels might have the same ID. Then, these labels\n",
    "                    # are mapped to the same class in the ground truth images. For the inverse\n",
    "                    # mapping, we use the label that is defined first in the list below.\n",
    "                    # For example, mapping all void-type classes to the same ID in training,\n",
    "                    # might make sense for some approaches.\n",
    "                    # Max value is 255!\n",
    "\n",
    "    'category'    , # The name of the category that this label belongs to\n",
    "\n",
    "    'categoryId'  , # The ID of this category. Used to create ground truth images\n",
    "                    # on category level.\n",
    "\n",
    "    'hasInstances', # Whether this label distinguishes between single instances or not\n",
    "\n",
    "    'ignoreInEval', # Whether pixels having this class as ground truth label are ignored\n",
    "                    # during evaluations or not\n",
    "\n",
    "    'color'       , # The color of this label\n",
    "    ] )\n",
    "\n",
    "labels = [\n",
    "    #       name                     id    trainId   category            catId     hasInstances   ignoreInEval   color\n",
    "    Label(  'unlabeled'            ,  0 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'ego vehicle'          ,  1 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'rectification border' ,  2 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'out of roi'           ,  3 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'static'               ,  4 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'dynamic'              ,  5 ,      255 , 'void'            , 0       , False        , True         , (111, 74,  0) ),\n",
    "    Label(  'ground'               ,  6 ,      255 , 'void'            , 0       , False        , True         , ( 81,  0, 81) ),\n",
    "    Label(  'road'                 ,  7 ,        0 , 'flat'            , 1       , False        , False        , (128, 64,128) ),\n",
    "    Label(  'sidewalk'             ,  8 ,        1 , 'flat'            , 1       , False        , False        , (244, 35,232) ),\n",
    "    Label(  'parking'              ,  9 ,      255 , 'flat'            , 1       , False        , True         , (250,170,160) ),\n",
    "    Label(  'rail track'           , 10 ,      255 , 'flat'            , 1       , False        , True         , (230,150,140) ),\n",
    "    Label(  'building'             , 11 ,        2 , 'construction'    , 2       , False        , False        , ( 70, 70, 70) ),\n",
    "    Label(  'wall'                 , 12 ,        3 , 'construction'    , 2       , False        , False        , (102,102,156) ),\n",
    "    Label(  'fence'                , 13 ,        4 , 'construction'    , 2       , False        , False        , (190,153,153) ),\n",
    "    Label(  'guard rail'           , 14 ,      255 , 'construction'    , 2       , False        , True         , (180,165,180) ),\n",
    "    Label(  'bridge'               , 15 ,      255 , 'construction'    , 2       , False        , True         , (150,100,100) ),\n",
    "    Label(  'tunnel'               , 16 ,      255 , 'construction'    , 2       , False        , True         , (150,120, 90) ),\n",
    "    Label(  'pole'                 , 17 ,        5 , 'object'          , 3       , False        , False        , (153,153,153) ),\n",
    "    Label(  'polegroup'            , 18 ,      255 , 'object'          , 3       , False        , True         , (153,153,153) ),\n",
    "    Label(  'traffic light'        , 19 ,        6 , 'object'          , 3       , False        , False        , (250,170, 30) ),\n",
    "    Label(  'traffic sign'         , 20 ,        7 , 'object'          , 3       , False        , False        , (220,220,  0) ),\n",
    "    Label(  'vegetation'           , 21 ,        8 , 'nature'          , 4       , False        , False        , (107,142, 35) ),\n",
    "    Label(  'terrain'              , 22 ,        9 , 'nature'          , 4       , False        , False        , (152,251,152) ),\n",
    "    Label(  'sky'                  , 23 ,       10 , 'sky'             , 5       , False        , False        , ( 70,130,180) ),\n",
    "    Label(  'person'               , 24 ,       11 , 'human'           , 6       , True         , False        , (220, 20, 60) ),\n",
    "    Label(  'rider'                , 25 ,       12 , 'human'           , 6       , True         , False        , (255,  0,  0) ),\n",
    "    Label(  'car'                  , 26 ,       13 , 'vehicle'         , 7       , True         , False        , (  0,  0,142) ),\n",
    "    Label(  'truck'                , 27 ,       14 , 'vehicle'         , 7       , True         , False        , (  0,  0, 70) ),\n",
    "    Label(  'bus'                  , 28 ,       15 , 'vehicle'         , 7       , True         , False        , (  0, 60,100) ),\n",
    "    Label(  'caravan'              , 29 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0, 90) ),\n",
    "    Label(  'trailer'              , 30 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0,110) ),\n",
    "    Label(  'train'                , 31 ,       16 , 'vehicle'         , 7       , True         , False        , (  0, 80,100) ),\n",
    "    Label(  'motorcycle'           , 32 ,       17 , 'vehicle'         , 7       , True         , False        , (  0,  0,230) ),\n",
    "    Label(  'bicycle'              , 33 ,       18 , 'vehicle'         , 7       , True         , False        , (119, 11, 32) ),\n",
    "    Label(  'license plate'        , -1 ,       -1 , 'vehicle'         , 7       , False        , True         , (  0,  0,142) ),\n",
    "]\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Main for testing\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# just a dummy main\n",
    "if __name__ == \"__main__\":\n",
    "    # Print all the labels\n",
    "    print(\"List of cityscapes labels:\")\n",
    "    print(\"\")\n",
    "    print(\"    {:>21} | {:>3} | {:>7} | {:>14} | {:>10} | {:>12} | {:>12}\".format( 'name', 'id', 'trainId', 'category', 'categoryId', 'hasInstances', 'ignoreInEval', 'color' ))\n",
    "    print(\"    \" + ('-' * 98))\n",
    "    for label in labels:\n",
    "        print(\"    {:>21} | {:>3} | {:>7} | {:>14} | {:>10} | {:>12} | {:>12}\".format( label.name, label.id, label.trainId, label.category, label.categoryId, label.hasInstances, label.ignoreInEval, label.color ))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deae723-4710-479e-9d21-22464d100d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catégories simplifiées\n",
    "categs = {\n",
    "    'void': [0, 1, 2, 3, 4, 5, 6],\n",
    "    'flat': [7, 8, 9, 10],\n",
    "    'construction': [11, 12, 13, 14, 15, 16],\n",
    "    'object': [17, 18, 19, 20],\n",
    "    'nature': [21, 22],\n",
    "    'sky': [23],\n",
    "    'human': [24, 25],\n",
    "    'vehicle': [26, 27, 28, 29, 30, 31, 32, 33, -1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c2cbf-cf8d-413f-80a8-ecb267974866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask(img):\n",
    "    \"\"\"\n",
    "    Simplifie les labels du masque en transformant les 32 sous-categs en 8 categs principales.\n",
    "    \"\"\"\n",
    "    mask = np.zeros((img.shape[0], img.shape[1], 8))\n",
    "    for i, cat in enumerate(categs.values()):  # Parcourt les catégories\n",
    "        mask[:, :, i] = np.isin(img, cat)  \n",
    "    return mask.astype(np.uint8)  # Assurer uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca5e16b-1342-465c-9afa-b815c6fb6f28",
   "metadata": {},
   "source": [
    "### 1.4.3 Colorisation du mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee23dc4a-f5b8-4f79-abd9-80b24c9ab1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire de couleurs avec des clés en entiers\n",
    "color_map = {\n",
    "    0: [50, 50, 50],     # void (gris foncé neutre)\n",
    "    1: [210, 180, 140],  # flat (ton sable/taupe)\n",
    "    2: [220, 120, 60],   # construction (brique/orange)\n",
    "    3: [255, 215, 0],    # object (jaune doré)\n",
    "    4: [60, 180, 75],    # nature (vert dynamique)\n",
    "    5: [135, 206, 235],  # sky (bleu ciel clair)\n",
    "    6: [255, 0, 0],      # human (rouge vif)\n",
    "    7: [0, 0, 255]       # vehicle (bleu vif)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20873bdc-559c-499c-8f85-9d8def8653bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dictionnaire de couleurs avec des clés en entiers\n",
    "# color_map = {\n",
    "#     0: [50, 50, 50],       # void\n",
    "#     1: [128, 64,128],   # flat\n",
    "#     2: [102,102,156], # construction\n",
    "#     3: [153,153,153],   # object\n",
    "#     4: [0, 255, 0],     # nature\n",
    "#     5: [0, 204, 204],   # sky\n",
    "#     6: [255, 0, 0],     # human\n",
    "#     7: [0, 0, 255]      # vehicle\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4c27f5-9395-4eb2-88de-fbe6d9d9febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dictionnaire de couleurs avec des clés en entiers\n",
    "# color_map = {\n",
    "#     0: [0, 0, 0],       # void\n",
    "#     1: [153, 153, 0],   # flat\n",
    "#     2: [255, 204, 204], # construction\n",
    "#     3: [255, 0, 127],   # object\n",
    "#     4: [0, 255, 0],     # nature\n",
    "#     5: [0, 204, 204],   # sky\n",
    "#     6: [255, 0, 0],     # human\n",
    "#     7: [0, 0, 255]      # vehicle\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1a38bc-572a-4837-8992-8dc28d699c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_color_map(mask):\n",
    "    \"\"\"\n",
    "    Applique une colormap personnalisée à un masque en niveaux de gris.\n",
    "    \"\"\"\n",
    "    h, w = mask.shape\n",
    "    color_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "    for label, color in color_map.items():\n",
    "        color_mask[mask == label] = color  # Remplace chaque pixel par sa couleur\n",
    "\n",
    "    return color_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be63b40-41c0-4555-8689-e483ceb49115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_color_map(mask):\n",
    "    \"\"\"\n",
    "    Applique une colormap personnalisée à un masque en one-hot encoding ou en indices. Pour la visualisation de la segmentation\n",
    "    \"\"\"\n",
    "    # Si le masque est en one-hot encoding, on le convertit en indices\n",
    "    if mask.ndim == 3 and mask.shape[-1] > 1:\n",
    "        mask = np.argmax(mask, axis=-1) # Transformation en single-channel pour affichage (on garde la classe la plus présente par pixel)\n",
    "\n",
    "    h, w = mask.shape\n",
    "    color_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "    for label, color in color_map.items():\n",
    "        color_mask[mask == label] = color  # Remplace chaque pixel par sa couleur\n",
    "\n",
    "    return color_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b907cad-a414-44b6-8b22-4126400a40b2",
   "metadata": {},
   "source": [
    "### 1.4.4 Process & save masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d56ee-c849-4b41-b3da-ca4e656aae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_masks(base_dir, mask_dir, save_dir, mask_type, mask_size):\n",
    "    \"\"\"\n",
    "    Traite et sauvegarde les masques de segmentation sous format .npy en conservant \n",
    "    la structure des dossiers d'origine (train/val). \n",
    "\n",
    "    Args:\n",
    "        base_dir (Path or str): Répertoire de base où enregistrer les masques convertis.\n",
    "        mask_dir (Path or str): Répertoire contenant les masques originaux.\n",
    "        mask_type (str, optional): Type de masque à filtrer. Default: \"_gtFine_labelIds\".\n",
    "        mask_size (tuple, optional): Taille cible des masques. Default: (256, 256).\n",
    "    \"\"\"\n",
    "\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)  # Création du dossier si inexistant\n",
    "\n",
    "    # Récupération des chemins des masques filtrés\n",
    "    mask_paths = get_mask_paths(mask_dir, mask_type=mask_type)\n",
    "\n",
    "    # Traitement des masques\n",
    "    for file_path in tqdm.tqdm(mask_paths, desc=\"Processing masks\"):\n",
    "        try:\n",
    "            # Déterminer le sous-dossier (train ou val)\n",
    "            relative_path = file_path.relative_to(mask_dir)\n",
    "            subdir = relative_path.parent  # Ex: train ou val\n",
    "\n",
    "            # Construire le chemin de sauvegarde\n",
    "            save_subdir = save_dir / subdir\n",
    "            save_subdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            save_path = save_subdir / (file_path.stem + \".npy\")\n",
    "\n",
    "            # Vérifier si le fichier existe déjà\n",
    "            if save_path.exists():\n",
    "                continue  # Évite de traiter un fichier déjà sauvegardé\n",
    "\n",
    "            # Vérification du format d'image\n",
    "            if file_path.suffix.lower() not in IMAGE_EXTENSIONS:\n",
    "                print(r\" /!\\  Fichier ignoré (mauvais format) : {file_path}\")\n",
    "                continue\n",
    "\n",
    "            # Chargement et conversion du masque\n",
    "            mask = image.load_img(file_path, color_mode=\"grayscale\", target_size=mask_size)\n",
    "            mask = np.array(mask, dtype=np.uint8)  # Convertir en tableau NumPy\n",
    "\n",
    "            # Simplification du masque\n",
    "            mask_simplified = make_mask(mask)\n",
    "\n",
    "            # Sauvegarde du masque simplifié\n",
    "            np.save(save_path, mask_simplified, allow_pickle=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"X Erreur lors du traitement de {file_path} : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a37de0f-2927-4763-a141-0ede38e66902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34a954f2-b72f-46f3-8dcf-1e3758feeff3",
   "metadata": {},
   "source": [
    "# 2. Data pre-processing & augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f2c80-ed5b-4473-9b90-97e45cb3742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition des chemins d'accès"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248415ca-e4fc-4431-9450-701fa63ac340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des chemins\n",
    "base_dir = Path(\"C:/Users/flore/Openclassrooms/Projet 8/data/original\") \n",
    "\n",
    "image_dir = base_dir / \"images\" # chemin du dossier d'images\n",
    "mask_dir = base_dir / \"masks\" # chemin du dossier de masques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a994b37-4bcd-4a44-9f68-5bf18d7f4d0c",
   "metadata": {},
   "source": [
    "pour un entrainement plus rapide des modèles, nous allons:\n",
    "* passer les masks de 32 sous categs à 8 categs principales\n",
    "* enregistrer les fichiers img sous le format .npy, plus rapide à charger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f374662c-9222-44dd-b290-3861d079c71f",
   "metadata": {},
   "source": [
    "## 2.1 Visualisation et simplification des catégories pour une image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44f9b9-b0ba-4641-9da9-c2926fb899d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Liste des images et des masques labelIds (segmentation sémantique)\n",
    "image_list = get_image_paths(image_dir)\n",
    "mask_list = get_mask_paths(mask_dir, mask_type=\"_gtFine_labelIds\")\n",
    "\n",
    "\n",
    "# Vérification du nombre d'images\n",
    "print(f\"Nombre d'images (hors Test): {len(image_list)}\")\n",
    "print(f\"Nombre de masques (hors Test): {len(mask_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba543651-c8b7-4dd1-a024-125ce6375069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement d'une image et de son masque correspondant:\n",
    "\n",
    "idx = 2830  # on peut tester différents indices\n",
    "image_path = image_list[idx]\n",
    "mask_path = mask_list[idx]\n",
    "\n",
    "# Chargement de l'image\n",
    "img = image.load_img(image_path)  # sans Resize\n",
    "img = image.img_to_array(img) / 255.0  # Normalisation\n",
    "\n",
    "# Chargement du masque\n",
    "mask = image.load_img(mask_path, color_mode=\"grayscale\")\n",
    "mask = np.array(mask, dtype=np.uint8)  # Convertir directement en entier pour garder les 8 labels\n",
    "\n",
    "mask_simplified = make_mask(mask) # Simplification du masque en 8 categs au lieu de 32;\n",
    "mask_colorized = apply_color_map(mask_simplified) # Colorisation\n",
    "\n",
    "\n",
    "# Affichage\n",
    "\n",
    "print(f\"Chemin de l'image : {image_path.relative_to(base_dir)}\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 10))\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title(\"Image originale\")\n",
    "ax[1].imshow(mask)\n",
    "ax[1].set_title(\"Masque labelID original\")\n",
    "ax[2].imshow(mask_colorized)\n",
    "ax[2].set_title(\"Masque labelID colorisé\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49478b78-7253-4161-b6fe-cf088983659a",
   "metadata": {},
   "source": [
    "## 2.2. Simplification categs et sauvegardes des masques en .npy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8446c3e-d380-4670-8720-99321b95c269",
   "metadata": {},
   "source": [
    "Étape\t           Image\t    Mask\n",
    "Redimensionnement\t✅ OUI\t    ✅ OUI\n",
    "Normalisation\t    ✅ /255\t❌ NON\n",
    "Format final\t(H, W, 3), float32\t(H, W, 8), one-hot encodé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d9066a-631b-451c-84f8-7fb55836dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dir = base_dir / \"masks_npy\"  # Dossier de sauvegarde des masques au format .npy\n",
    "# os.makedirs(save_dir, exist_ok=True)  # Création si inexistant\n",
    "\n",
    "# mask_type = \"_gtFine_labelIds\"\n",
    "# mask_size = (256, 256)\n",
    "\n",
    "# # Récupération des chemins des masques filtrés\n",
    "# mask_paths = get_mask_paths(mask_dir, mask_type=mask_type)\n",
    "\n",
    "# # Traitement des masques\n",
    "# for file_path in tqdm.tqdm(mask_paths):\n",
    "#     try:\n",
    "#         # Déterminer le sous-dossier (train ou val)\n",
    "#         relative_path = file_path.relative_to(mask_dir)\n",
    "#         subdir = relative_path.parent  # Récupérer le sous-dossier (ex: train ou val)\n",
    "\n",
    "#         # Construire le chemin de sauvegarde en répliquant la structure\n",
    "#         save_subdir = save_dir / subdir\n",
    "#         save_subdir.mkdir(parents=True, exist_ok=True)  # Création récursive du dossier\n",
    "\n",
    "#         # Création du chemin de sauvegarde\n",
    "#         save_path = save_subdir / (file_path.stem + \".npy\")\n",
    "\n",
    "#         # Vérifier si le fichier existe déjà\n",
    "#         if save_path.exists():\n",
    "#             continue  # Passer au fichier suivant\n",
    "\n",
    "#         # Vérification du format d'image avant chargement\n",
    "#         if file_path.suffix.lower() not in IMAGE_EXTENSIONS:\n",
    "#             print(f\" /!\\  Fichier ignoré (mauvais format) : {file_path}\")\n",
    "#             continue\n",
    "\n",
    "#         # Chargement du masque\n",
    "#         mask = image.load_img(file_path,  color_mode=\"grayscale\", target_size=mask_size)\n",
    "#         mask = np.array(mask, dtype=np.uint8)  # Convertir directement en entier\n",
    "\n",
    "#         # Simplification du masque\n",
    "#         mask_simplified = make_mask(mask)\n",
    "\n",
    "#         # Création du chemin de sauvegarde\n",
    "#         save_path = save_subdir / (file_path.stem + \".npy\")\n",
    "\n",
    "#         # Sauvegarde du masque simplifié\n",
    "#         np.save(save_path, mask_simplified)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"X Erreur lors du traitement de {file_path} : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a8a89-a0d0-427c-9417-3e627255a8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(base_dir) /  \"masks_npy\"\n",
    "mask_type = \"_gtFine_labelIds\"\n",
    "mask_size = (256, 256)\n",
    "\n",
    "process_and_save_masks(base_dir, mask_dir, save_dir, mask_type, mask_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58edb048-77c8-437a-ad53-76f628dafcb6",
   "metadata": {},
   "source": [
    "## 2.3. Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e8615-2449-4940-a558-41e5218da365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des transformations pour l'augmentation\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=15, p=0.5),\n",
    "    A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.3),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),\n",
    "    A.GaussNoise(var_limit=(10, 50), p=0.2),\n",
    "    A.CoarseDropout(max_holes=5, max_height=50, max_width=50, p=0.3),\n",
    "], additional_targets={'mask': 'mask'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58690bc7-54cc-49bc-bf9d-4c3967cc971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dossiers source & destination\n",
    "base_dir = Path(\"C:/Users/flore/Openclassrooms/Projet 8/data\")\n",
    "image_dir = base_dir / \"original\" / \"images\"\n",
    "mask_dir = base_dir / \"original\" / \"masks\"\n",
    "augmented_dir = base_dir / \"augmented\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e816002d-9385-465d-afab-ec3c669131d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramétrages:\n",
    "mask_type = \"_gtFine_labelIds\"\n",
    "target_size = (256, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe28bb-359b-46c7-ac51-998a8b18155e",
   "metadata": {},
   "source": [
    "Applique une augmentation aux images et leurs masques, enregistre l'image augmentée en PNG et le masque en .npy.\n",
    "Resize (256,256) APRES l'augmentation pour éviter la perte d'information. resize permet de passer au modele des images légères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27414f92-30e9-4597-bc9f-bde1c978ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des images\n",
    "image_paths = get_image_paths(image_dir)\n",
    "\n",
    "for image_path in tqdm.tqdm(image_paths, desc=\"Processing images & masks\"):\n",
    "    try:\n",
    "        # Déterminer le sous-dossier (train ou val)\n",
    "        relative_path = image_path.relative_to(image_dir)\n",
    "        subdir = relative_path.parent  # Ex: train ou val\n",
    "\n",
    "        # Construire les chemins de sauvegarde\n",
    "        save_image_subdir = augmented_dir / \"images\" / subdir\n",
    "        save_mask_subdir = augmented_dir / \"masks_npy\" / subdir  # Stockage des masques en .npy ici\n",
    "\n",
    "        # Création des dossiers parents si nécessaire\n",
    "        save_image_subdir.mkdir(parents=True, exist_ok=True)\n",
    "        save_mask_subdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Définition des chemins finaux des fichiers sauvegardés\n",
    "        save_image_path = save_image_subdir / f\"{image_path.stem}.png\"\n",
    "        save_mask_path = save_mask_subdir / f\"{image_path.stem}.npy\"\n",
    "\n",
    "        # Vérification si le masque existe bien pour l'image donnée\n",
    "        mask_relative_path = image_path.relative_to(image_dir)  # Récupération du chemin relatif\n",
    "        mask_name = image_path.stem.replace(\"_leftImg8bit\", \"\") # récupération du nom de base sans `_leftImg8bit`\n",
    "        mask_path = mask_dir / mask_relative_path.parent / f\"{mask_name}_gtFine_labelIds.png\"\n",
    "\n",
    "        if not mask_path.exists():\n",
    "            print(f\"Masque non trouvé pour {image_path.name}, passage...\")\n",
    "            continue\n",
    "\n",
    "        # Chargement de l'image et du masque sans redimensionnement\n",
    "        img = image.load_img(image_path)  # Chargement en RGB, taille originale\n",
    "        mask = image.load_img(mask_path, color_mode=\"grayscale\")  # Chargement en niveaux de gris\n",
    "\n",
    "        img = np.array(img)\n",
    "        mask = np.array(mask, dtype=np.uint8)  # Convertir en tableau NumPy\n",
    "\n",
    "        # Vérification que tout est OK\n",
    "        if img is None or mask is None:\n",
    "            print(f\"Problème de chargement pour {image_path.name}, passage...\")\n",
    "            continue\n",
    "\n",
    "        # Appliquer l'augmentation aux images et aux masques\n",
    "        augmentation = transform(image=img, mask=mask)\n",
    "        image_aug, mask_aug = augmentation[\"image\"], augmentation[\"mask\"]\n",
    "\n",
    "        # Resize après augmentation\n",
    "        image_aug = cv2.resize(image_aug, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "        mask_aug = cv2.resize(mask_aug, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Simplification des catégories du masque (ex: de 34 à 8 classes)\n",
    "        mask_simplified = make_mask(mask_aug)\n",
    "\n",
    "        # Sauvegarde des fichiers\n",
    "        cv2.imwrite(str(save_image_path), image_aug)\n",
    "        np.save(save_mask_path, mask_simplified, allow_pickle=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur sur {image_path.name} : {e}\")\n",
    "\n",
    "print(\"Augmentation terminée !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476e8412-bdf7-46a2-b46e-cabc15f384e4",
   "metadata": {},
   "source": [
    "# 3. DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5d0120-d601-4ea8-92d7-fc81aff8a2f7",
   "metadata": {},
   "source": [
    "le DataGenerator est un script python sauvegardé dans le meme dossier que ce notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b53b50-b261-435b-abcb-3da2ea6d127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataGenerator import DataGenerator\n",
    "\n",
    "# paramétrage\n",
    "batch_size = 32\n",
    "img_size=(256, 256)\n",
    "\n",
    "# chemins d'accès (uniquement avec les images d'origines):\n",
    "base_dir = Path(\"C:/Users/flore/Openclassrooms/Projet 8/data/original\")\n",
    "train_image_dir = base_dir / \"images\" / \"train\"\n",
    "train_mask_dir = base_dir / \"masks_npy\"/ \"train\"\n",
    "val_image_dir = base_dir / \"images\" / \"val\"\n",
    "val_mask_dir = base_dir / \"masks_npy\"/ \"val\"\n",
    "\n",
    "\n",
    "train_image_paths = get_image_paths (train_image_dir)\n",
    "train_mask_paths = get_mask_paths (train_mask_dir)\n",
    "val_image_paths = get_image_paths (val_image_dir)\n",
    "val_mask_paths = get_mask_paths (val_mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baa73aa-6801-47c2-bbb9-e5d8d4e0582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation du générateur\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    image_paths=train_image_paths,\n",
    "    mask_paths=train_mask_paths,\n",
    "    batch_size=batch_size,\n",
    "    img_size=img_size,\n",
    "    num_classes=8,\n",
    "    augmentation=transform,\n",
    "    one_hot=True,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = DataGenerator(\n",
    "    image_paths=val_image_paths,\n",
    "    mask_paths=val_mask_paths,\n",
    "    batch_size=batch_size,\n",
    "    img_size=img_size,\n",
    "    num_classes=8,\n",
    "    one_hot=True,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836c093-bd2f-421c-ab48-7bdb672e601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test du data generator\n",
    "# Récupérer un batch\n",
    "X, Y = train_generator[0]\n",
    "\n",
    "# Vérifier les formes des données\n",
    "print(\"Shape des images :\", X.shape)  # Doit être (batch_size, img_size, img_size, 3)\n",
    "print(\"Shape des masques :\", Y.shape)  # Si one-hot activé : (batch_size, img_size, img_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14cdea7-76de-4eb4-af0e-6a1f8199d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c3a79-fa33-4edd-9934-879cf01304c3",
   "metadata": {},
   "source": [
    "### 4.1 Regression log avec CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371c5449-e4f8-4b71-b11b-4ebdcd93c04c",
   "metadata": {},
   "source": [
    "CountVectorizer\tconvertit le texte en une matrice d'occurrences de mots.\t\n",
    "* **Avantages**: Simple, rapide à exécuter, efficace pour des vocabulaires réduits.\t\n",
    "* **Inconvénients**: Ne capture pas la sémantique ou l'ordre des mots ; sensible à la taille du vocabulaire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9b2c80-4750-4542-9fa9-dd43993daf9c",
   "metadata": {},
   "source": [
    "Definition du modèle: une regression logistique, sans hyper-parmètres de départ. Ils seront ensuite affinés via l'optimisation des hyperparamètres (grid_searchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0251f2d-cdc0-4df4-8870-c48251d6f64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Log Reg with CountVectorizer\"):\n",
    "\n",
    "    mlflow.set_tag(\"Approach\", \"CountVectorizer\")\n",
    "\n",
    "    #----------------------------\n",
    "    # Hyperparamètres\n",
    "    params = {\n",
    "        \"C\": 1, #[0.01, 0.1, 1, 10, 100]\n",
    "        \"solver\": 'lbfgs', #'newton-cg','lbfgs','liblinear', 'saga']\n",
    "        \"penalty\": 'l2', #['l1', 'l2'], \n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "    }\n",
    "    mlflow.log_params(params) #log des paramètres\n",
    "\n",
    "    #----------------------------\n",
    "    # Modèle et pipeline\n",
    "    model = LogisticRegression(**params)\n",
    "    pipeline = make_pipeline(\n",
    "        CountVectorizer(stop_words='english', max_df=0.95, min_df=2), # Etape 1: transformation des features en vecteur\n",
    "        model                                                         # Étape 2 : Modèle de regression logistique \n",
    "    )\n",
    "    # pipeline = Pipeline([\n",
    "    #     ('vectorizer', CountVectorizer(stop_words='english', max_df=0.95, min_df=2)), # Etape 1: transformation des features en vecteur\n",
    "    #     ('model', model)                                      # Étape 2 : Modèle de regression logistique\n",
    "    # ])\n",
    "    \n",
    "    # Log du pipeline\n",
    "    mlflow.sklearn.log_model(pipeline, \"LogReg_CountVectorizer\")\n",
    "\n",
    "    \n",
    "    #----------------------------\n",
    "    # Calcul de l'accuracy, sans rechercher le seuil optimal\n",
    "    cv_scores_pipeline = cross_val_score(pipeline, data['sentence_bow_lem'], data['target'], cv=5, scoring='accuracy')\n",
    "    # mlflow.log_metric(\"Accuracy sans seuil optimal\", round(np.mean(cv_scores_pipeline),3))\n",
    "\n",
    "    #----------------------------\n",
    "    # Prédiction et métrics en recherchant le seuil optimal\n",
    "    # Utilisation de 'predict_proba' pour obtenir les probabilités\n",
    "    y_proba = cross_val_predict(pipeline, data['sentence_bow_lem'], data['target'], cv=5, method='predict_proba')\n",
    "    results, conf_matrix = model_metrics(data['target'], y_proba)\n",
    "    \n",
    "    #logs des résultats dans MLflow:\n",
    "    mlflow.log_metric(\"Accuracy\", results['Accuracy'][-1])\n",
    "    mlflow.log_metric(\"F1_Score\", results['F1-score'][-1])\n",
    "    mlflow.log_metric(\"Coût métier\", results['Coût métier'][-1])\n",
    "    mlflow.log_metric(\"FN\", results['FN'][-1])\n",
    "    mlflow.log_metric(\"FP\", results['FP'][-1])\n",
    "\n",
    "    #----------------------------\n",
    "    # Matrice de confusion\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(\"Matrice de confusion avec seuil optimal\")\n",
    "    plt.xlabel(\"Prédictions\")\n",
    "    plt.ylabel(\"Vrais labels\")\n",
    "    \n",
    "    # Enregistrement avant affichage\n",
    "    plt.savefig(\"conf_matrix.png\")\n",
    "    mlflow.log_artifact(\"conf_matrix.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef22b12-a01e-4889-b2a6-ff705ef55fc7",
   "metadata": {},
   "source": [
    "### 4.2  Regression log avec TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74a5c6e-fcc1-4d85-bbbc-8c987f299331",
   "metadata": {},
   "source": [
    "TF-IDF = Term Frequency - Inverse Document Frequency\n",
    "On pondère l'importance d'un mot dans un document, par rapport à l'ensemble du corpus (ici tous nos articles vendus sur le site e-com)\n",
    "\n",
    "* **Avantages:** Meilleure différenciation entre les termes fréquents et rares, réduit l'impact des mots peu informatifs.\n",
    "* **Inconvénients:** là encore, insensible à l'ordre et au contexte des mots ; dépend du corpus pour une bonne pondération."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f733a5b0-64d1-458b-ad38-ea67889cc7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Log Reg with TF-IDF\"):\n",
    "\n",
    "    mlflow.set_tag(\"Approach\", \"TF-IDF\")\n",
    "\n",
    "    #----------------------------\n",
    "    # Hyperparamètres\n",
    "    params = {\n",
    "        \"C\": 1, #[0.01, 0.1, 1, 10, 100]\n",
    "        \"solver\": 'lbfgs', #'newton-cg','lbfgs','liblinear', 'saga']\n",
    "        \"penalty\": 'l2', #['l1', 'l2'], \n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "    }\n",
    "    mlflow.log_params(params) #log des paramètres\n",
    "\n",
    "    #----------------------------\n",
    "    # Modèle et pipeline\n",
    "    model = LogisticRegression(**params)\n",
    "    pipeline = make_pipeline(\n",
    "        TfidfVectorizer(stop_words='english', max_df=0.95, min_df=2), # Etape 1: transformation des features en vecteur\n",
    "        model                                                         # Étape 2 : Modèle de regression logistique \n",
    "    )\n",
    "    # Log du pipeline\n",
    "    mlflow.sklearn.log_model(pipeline, \"LogReg_TF_IDF\")\n",
    "\n",
    "\n",
    "    \n",
    "    #----------------------------\n",
    "    # Calcul de l'accuracy, sans rechercher le seuil optimal\n",
    "    cv_scores_pipeline = cross_val_score(pipeline, data['sentence_bow_lem'], data['target'], cv=5, scoring='accuracy')\n",
    "    # mlflow.log_metric(\"Accuracy sans seuil optimal\", round(np.mean(cv_scores_pipeline),3))\n",
    "\n",
    "    #----------------------------\n",
    "    # Prédiction et métrics en recherchant le seuil optimal\n",
    "    # Utilisation de 'predict_proba' pour obtenir les probabilités\n",
    "    y_proba = cross_val_predict(pipeline, data['sentence_bow_lem'], data['target'], cv=5, method='predict_proba')\n",
    "    results, conf_matrix = model_metrics(data['target'], y_proba)\n",
    "    \n",
    "    #logs des résultats dans MLflow:\n",
    "    mlflow.log_metric(\"Accuracy\", results['Accuracy'][-1])\n",
    "    mlflow.log_metric(\"F1_Score\", results['F1-score'][-1])\n",
    "    mlflow.log_metric(\"Coût métier\", results['Coût métier'][-1])\n",
    "    mlflow.log_metric(\"FN\", results['FN'][-1])\n",
    "    mlflow.log_metric(\"FP\", results['FP'][-1])\n",
    "\n",
    "    #----------------------------\n",
    "    # Matrice de confusion\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(\"Matrice de confusion avec seuil optimal\")\n",
    "    plt.xlabel(\"Prédictions\")\n",
    "    plt.ylabel(\"Vrais labels\")\n",
    "    \n",
    "    # Enregistrement avant affichage\n",
    "    plt.savefig(\"conf_matrix.png\")\n",
    "    mlflow.log_artifact(\"conf_matrix.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b4d2fb-fc59-4ae9-aa0c-31b93b37edfd",
   "metadata": {},
   "source": [
    "# 5. Approche “Modèle sur mesure avancé”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd246ee-2727-41d0-9f99-a15db1175c0a",
   "metadata": {},
   "source": [
    "Pour l'approche \"modèle sur mesure avancé, nous allons utiliser différents réseaux profonds de neurones classique (DNN ou deep neural network) pour classifier les sentiments des tweets de facon binaire (positif ou negatif).\n",
    "Nous allons tester 2 techniques d'embeddings, pour obtenir des vecteurs qui caractérisent chacun des tweets:\n",
    "* Word2Vec\n",
    "* FastText\n",
    "Après le test de ces différents modèles couplés à Word2Vec et FastText, nous finirons en testant la performance de BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a63262f-1c18-4bd5-b1a9-87a23ba3ca43",
   "metadata": {},
   "source": [
    "## 5.1 DNN avec Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fffa84-9d4d-4acb-be2b-afa14ded1f6d",
   "metadata": {},
   "source": [
    "Word2Vec apprend des représentations vectorielles denses pour les mots en utilisant des architectures de réseau neuronal (CBOW ou Skip-gram). \n",
    "Les mots proches dans l’espace vectoriel partagent des similarités contextuelles. \n",
    "\n",
    "* **Avantages:** Capture les relations sémantiques entre les mots, représentations continues adaptées aux modèles ML.\n",
    "* **Inconvénients:** Nécessite un grand corpus pour des embeddings de qualité ; insensible aux structures complexes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d562bf6-047a-4a81-a712-e72c5159d3c4",
   "metadata": {},
   "source": [
    "**DNN (Deep Neural Network)**\n",
    "\n",
    "* Type : Réseau de neurones dense (Fully Connected)\n",
    "  \n",
    "* Caractéristiques :\n",
    "Réseau simple avec des couches Dense (MLP - Multi-Layer Perceptron)\n",
    "Relu pour l'activation des couches cachées, sigmoid pour la sortie (binaire)\n",
    "Dropout et régularisation pour éviter l'overfitting\n",
    "\n",
    "* C'est un empilement de couches de neurones connectés entre eux. Chaque neurone reçoit des nombres (features d'entrée), les transforme avec des calculs (poids + biais), applique une fonction d’activation (ex: ReLU) et envoie le résultat à la couche suivante.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2826499-3177-42ee-8b16-baf92f4c7577",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"DNN with Word2Vec\"):\n",
    "    mlflow.set_tag(\"Approach\", \"Word2Vec + DNN\")\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 1. Paramétrage du modèle\n",
    "    #-------------------------------------------------\n",
    "    params = {\n",
    "        # Word2Vec\n",
    "        \"vector_size\": 100,     # Dimension des vecteurs\n",
    "        \"window\": 5,     # Taille de la fenêtre contextuelle\n",
    "        \"min_count\": 1,  # Ignore les mots rares\n",
    "        \"epochs\": 50,   # Nombre d'itérations d'entraînement sur les données\n",
    "        # DNN\n",
    "        \"dropout_rate\": 0.3, #[None, 0.3, 0.5]\n",
    "        \"regularization\": l2(0.01), #[None, l1(0.01), l2(0.01)] \n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    #-------------------------------------------------\n",
    "    # 2. Création du modèle Word2Vec sur l'ensemble du corpus\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    tokenized_tweets = [text.split() for text in data['sentence_bow_lem']]\n",
    "    \n",
    "    w2v_model = Word2Vec(\n",
    "        sentences=tokenized_tweets,\n",
    "        vector_size=params[\"vector_size\"],  \n",
    "        window=params[\"window\"],\n",
    "        min_count=params[\"min_count\"],\n",
    "        epochs=params[\"epochs\"],\n",
    "        workers=10\n",
    "    )\n",
    "\n",
    "    # Sauvegarde du modèle Word2Vec dans MLflow\n",
    "    w2v_model_path = \"word2vec.model\"\n",
    "    w2v_model.save(w2v_model_path)\n",
    "    mlflow.log_artifact(w2v_model_path, artifact_path=\"word2vec\")\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 3. Obtention des vecteurs pour chaque tweet\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    def get_sentence_vector(sentence, model, dim):\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        return np.mean(vectors, axis=0) if vectors else np.zeros(dim)\n",
    "    \n",
    "    X = np.array([get_sentence_vector(text, w2v_model, params[\"vector_size\"]) for text in tokenized_tweets])\n",
    "    y = data['target'].reset_index(drop=True)\n",
    "\n",
    "    #-------------------------------------------------\n",
    "    # 4. Split en train/test (85/15)\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 5. Construction du modèle DNN\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    # Modèle DNN\n",
    "    model = Sequential([\n",
    "        Input(shape=(params[\"vector_size\"],)),\n",
    "        Dense(64, activation='relu', kernel_regularizer=params[\"regularization\"]),\n",
    "        Dropout(params[\"dropout_rate\"]),\n",
    "        Dense(32, activation='relu', kernel_regularizer=params[\"regularization\"]),\n",
    "        Dropout(params[\"dropout_rate\"]),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=TfAdam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Early Stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 6. Entraînement du modèle & Prédiction\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=16,\n",
    "        validation_split=0.15,\n",
    "        #verbose=0,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    \n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "    #-------------------------------------------------\n",
    "    # 7. Résultats \n",
    "    #-------------------------------------------------\n",
    "\n",
    "    show_history(history)\n",
    "    plot_history(history, path=f\"training_history.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    cout_metier = fp + fn\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Matrice de confusion:\\n\", conf_matrix)\n",
    "    print(\"Coût métier:\", cout_metier)\n",
    "    \n",
    "    mlflow.log_metric(\"Accuracy\", round(accuracy, 3))\n",
    "    mlflow.log_metric(\"F1_Score\", round(f1, 3))\n",
    "    mlflow.log_metric(\"Coût métier\", cout_metier)\n",
    "    mlflow.log_metric(\"FN\", fn)\n",
    "    mlflow.log_metric(\"FP\", fp)\n",
    "    \n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "    mlflow.keras.log_model(model, \"DNN_Model\", signature=signature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2055d35a-d2fb-4e59-82ee-8506f22e25ae",
   "metadata": {},
   "source": [
    "## 5.2 DNN avec FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380eb1da-b10d-451b-9aed-580498dbc4eb",
   "metadata": {},
   "source": [
    "FastText est une technique d'embedding qui apprend des représentations vectorielles denses pour les mots en utilisant des architectures de réseau neuronal (CBOW ou Skip-gram). Contrairement à Word2Vec, il représente chaque mot comme une somme de vecteurs de sous-mots (n-grammes), ce qui permet une meilleure généralisation sur les mots rares ou inconnus. Les mots proches dans l’espace vectoriel partagent des similarités contextuelles et morphologiques.  \n",
    "\n",
    "* **Avantages:** Capture les relations sémantiques et morphologiques entre les mots, gère mieux les mots rares ou inconnus, et améliore la robustesse aux fautes d’orthographe.  \n",
    "* **Inconvénients:** Plus gourmand en mémoire et en calcul que Word2Vec ; nécessite un tuning des n-grammes pour de meilleurs résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1713da39-8ca5-40f0-a709-db322e95d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"DNN with FastText\"):\n",
    "    \n",
    "    mlflow.set_tag(\"Approach\", \"FastText + DNN\")\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 1. Paramétrage du modèle\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    params = {\n",
    "        #FastText\n",
    "        \"vector_size\": 100,     # Dimension des vecteurs\n",
    "        \"window\": 5,     # Taille de la fenêtre contextuelle\n",
    "        \"min_count\": 1,  # Ignore les mots rares\n",
    "        \"epochs\": 100,   # Nombre d'itérations d'entraînement sur les données\n",
    "        # DNN\n",
    "        \"dropout_rate\": 0.3, #[None, 0.3, 0.5]\n",
    "        \"regularization\": l2(0.01), #[None, l1(0.01), l2(0.01)] \n",
    "    }\n",
    "\n",
    "    \n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # obtention des tweets tokenisés:\n",
    "    tokenized_tweets = [text.split() for text in data['sentence_bow_lem']]\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 2. Création du modèle FastText sur l'ensemble du corpus\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    ft_model = FastText(\n",
    "        sentences=tokenized_tweets,\n",
    "        vector_size=params[\"vector_size\"],  \n",
    "        window=params[\"window\"],\n",
    "        min_count=params[\"min_count\"],\n",
    "        epochs=params[\"epochs\"],\n",
    "        workers=10\n",
    "    )\n",
    "\n",
    "    # Sauvegarde du modèle FastText dans MLflow an tant qu'artifact:\n",
    "    ft_model_path = \"fasttext.model\"\n",
    "    ft_model.save(ft_model_path)\n",
    "    mlflow.log_artifact(ft_model_path, artifact_path=\"FastText\")\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 3. Obtention des vecteurs pour chaque tweet\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    def get_sentence_vector(sentence, model, dim):\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        return np.mean(vectors, axis=0) if vectors else np.zeros(dim)\n",
    "\n",
    "    \n",
    "    X = np.array([get_sentence_vector(text, ft_model, params[\"vector_size\"]) for text in tokenized_tweets])\n",
    "    y = data['target'].reset_index(drop=True)\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 4. Split en train/test (85/15)\n",
    "    #-------------------------------------------------\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    # 5. Construction du modèle DNN\n",
    "    # -------------------------------------------------\n",
    "    model = Sequential([\n",
    "        Input(shape=(params[\"vector_size\"],)),\n",
    "        Dense(64, activation='relu', kernel_regularizer=params[\"regularization\"]),\n",
    "        Dropout(params[\"dropout_rate\"]),\n",
    "        Dense(32, activation='relu', kernel_regularizer=params[\"regularization\"]),\n",
    "        Dropout(params[\"dropout_rate\"]),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "        \n",
    "    # model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(optimizer=TfAdam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 6. Entraînement du modèle & Prédiction\n",
    "    #-------------------------------------------------\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=16,\n",
    "        validation_split=0.15,\n",
    "        #verbose=0,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    \n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "    #-------------------------------------------------\n",
    "    # 7. Résultats \n",
    "    #-------------------------------------------------\n",
    "\n",
    "    show_history(history)\n",
    "    plot_history(history, path=f\"training_history.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    cout_metier = fp + fn\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Matrice de confusion:\\n\", conf_matrix)\n",
    "    print(\"Coût métier:\", cout_metier)\n",
    "    \n",
    "    # Logs des résultats dans MLflow\n",
    "    mlflow.log_metric(\"Accuracy\", round(accuracy, 3))\n",
    "    mlflow.log_metric(\"F1_Score\", round(f1, 3))\n",
    "    mlflow.log_metric(\"Coût métier\", cout_metier)\n",
    "    mlflow.log_metric(\"FN\", fn)\n",
    "    mlflow.log_metric(\"FP\", fp)\n",
    "    \n",
    "    # Enregistrement du modèle DNN dans MLflow\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "    mlflow.keras.log_model(model, \"DNN_Model\", signature=signature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d5cfbb-f0a7-462b-ad0a-e654725c9658",
   "metadata": {},
   "source": [
    "## 5.3 CNN avec FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97283b9d-cfb0-4193-9c09-e517dd19399c",
   "metadata": {},
   "source": [
    "**CNN (Convolutional Neural Network)**\n",
    "\n",
    "* Type : Réseau de neurones convolutionnel (1D)\n",
    "  \n",
    "* Caractéristiques : Conv1D applique des filtres pour capturer des patterns locaux dans les séquences\n",
    "MaxPooling réduit la dimension tout en conservant les informations importantes\n",
    "Flatten transforme les sorties convolutives en un vecteur pour la classification\n",
    "Relu pour l'activation, sigmoid pour la sortie binaire.\n",
    "\n",
    "* Au lieu de tout connecter comme un DNN, un CNN applique des filtres (Conv1D) qui glissent sur l’entrée (ex: un texte). Ces filtres repèrent des motifs récurrents comme des mots-clés ou des groupes de mots. Ensuite, le max-pooling réduit la taille tout en gardant l’essentiel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdfbd42-cde2-4583-8aac-d9ed339cfe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"CNN with FastText\"):\n",
    "    \n",
    "    mlflow.set_tag(\"Approach\", \"FastText + CNN\")\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 1. Paramétrage du modèle\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    params = {\n",
    "        #FastText\n",
    "        \"vector_size\": 100,     # Dimension des vecteurs\n",
    "        \"window\": 5,     # Taille de la fenêtre contextuelle\n",
    "        \"min_count\": 1,  # Ignore les mots rares\n",
    "        \"epochs\": 100,   # Nombre d'itérations d'entraînement sur les données\n",
    "        # CNN\n",
    "        \"dropout_rate\": 0.3, #[None, 0.3, 0.5]\n",
    "        \"regularization\": l2(0.01), #[None, l1(0.01), l2(0.01)] \n",
    "    }\n",
    "    \n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # obtention des tweets tokenisés:\n",
    "    tokenized_tweets = [text.split() for text in data['sentence_bow_lem']]\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 2. Création du modèle FastText sur l'ensemble du corpus\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    ft_model = FastText(\n",
    "        sentences=tokenized_tweets,\n",
    "        vector_size=params[\"vector_size\"],  \n",
    "        window=params[\"window\"],\n",
    "        min_count=params[\"min_count\"],\n",
    "        epochs=params[\"epochs\"],\n",
    "        workers=10\n",
    "    )\n",
    "    \n",
    "    # Sauvegarde du modèle FastText dans MLflow an tant qu'artifact:\n",
    "    ft_model_path = \"fasttext.model\"\n",
    "    ft_model.save(ft_model_path)\n",
    "    mlflow.log_artifact(ft_model_path, artifact_path=\"FastText\")\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 3. Obtention des vecteurs pour chaque tweet\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    def get_sentence_vector(sentence, model, dim):\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        return np.mean(vectors, axis=0) if vectors else np.zeros(dim)\n",
    "    \n",
    "    X = np.array([get_sentence_vector(text, ft_model, params[\"vector_size\"]) for text in tokenized_tweets])\n",
    "    y = data['target'].reset_index(drop=True)\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 4. Split en train/test (85/15)\n",
    "    #-------------------------------------------------\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    # 5. Construction du modèle CNN\n",
    "    # -------------------------------------------------\n",
    "    model = Sequential([\n",
    "        Input(shape=(params[\"vector_size\"], 1)),  # Ajout d'une dimension pour les filtres CNN\n",
    "        Conv1D(64, 5, activation='relu', kernel_regularizer=params[\"regularization\"]),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(params[\"dropout_rate\"]),\n",
    "        Conv1D(32, 5, activation='relu', kernel_regularizer=params[\"regularization\"]),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(optimizer=TfAdam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 6. Entraînement du modèle & Prédiction\n",
    "    #-------------------------------------------------\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=16,\n",
    "        validation_split=0.15,\n",
    "        #verbose=0,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "    #-------------------------------------------------\n",
    "    # 7. Résultats \n",
    "    #-------------------------------------------------\n",
    "\n",
    "    show_history(history)\n",
    "    plot_history(history, path=f\"training_history.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    cout_metier = fp + fn\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Matrice de confusion:\\n\", conf_matrix)\n",
    "    print(\"Coût métier:\", cout_metier)\n",
    "    \n",
    "    # Logs des résultats dans MLflow\n",
    "    mlflow.log_metric(\"Accuracy\", round(accuracy, 3))\n",
    "    mlflow.log_metric(\"F1_Score\", round(f1, 3))\n",
    "    mlflow.log_metric(\"Coût métier\", cout_metier)\n",
    "    mlflow.log_metric(\"FN\", fn)\n",
    "    mlflow.log_metric(\"FP\", fp)\n",
    "    \n",
    "    # Enregistrement du modèle CNN dans MLflow\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "    mlflow.keras.log_model(model, \"CNN_Model\", signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5082463-65f9-44f6-9005-933bec4f76e2",
   "metadata": {},
   "source": [
    "## 5.3 BiLSTM avec FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b924ca-b271-4b3f-adbe-adae7fc5c84a",
   "metadata": {},
   "source": [
    "**BiLSTM (Bidirectional LSTM)**\n",
    "\n",
    "* Type : Réseau de neurones récurrent (RNN) avec Long Short-Term Memory (LSTM)\n",
    "\n",
    "* Caractéristiques :\n",
    "Bidirectionnel (BiLSTM) → Lit la séquence dans les deux sens (avant et arrière)\n",
    "Meilleur que CNN pour les dépendances longues\n",
    "Dropout + Dense pour éviter l'overfitting\n",
    "Sigmoid pour la sortie binaire\n",
    "\n",
    "* C’est un réseau séquentiel qui lit les données dans les deux sens (gauche → droite et droite → gauche). Il stocke une mémoire à long terme pour comprendre le contexte d’un texte. Contrairement au CNN, il sait que \"chat noir\" et \"noir chat\" ne sont pas les mêmes choses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc62308-31e3-46ea-b3ef-1e838fadda4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"LSTM with FastText & CNN\"):\n",
    "    \n",
    "    mlflow.set_tag(\"Approach\", \"FastText + CNN + BiLSTM\")\n",
    "    \n",
    "    \n",
    "#-------------------------------------------------\n",
    "# 1. Paramétrage du modèle\n",
    "#-------------------------------------------------\n",
    "\n",
    "\n",
    "    params = {\n",
    "        # FastText\n",
    "        \"vector_size\": 100,     # Taille des vecteurs\n",
    "        \"window\": 5,            # Fenêtre contextuelle\n",
    "        \"min_count\": 1,         # Ignore les mots rares\n",
    "        \"epochs\": 50,           # Nombre d'epochs pour FastText\n",
    "        # LSTM\n",
    "        \"batch_size\": 32,       # Taille des batches pour LSTM\n",
    "        \"lstm_units\": 128,       # Nombre de neurones LSTM (BiLSTM donc 2x)\n",
    "        \"dropout_rate\": 0.5,    # Taux de Dropout\n",
    "        \"conv_filters\": 64,     # Filtres pour la couche Conv1D\n",
    "        \"conv_kernel_size\": 5   # Taille du noyau Conv1D\n",
    "    }\n",
    "    \n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # Obtention des tweets tokenisés\n",
    "    tokenized_tweets = [text.split() for text in data['sentence_bow_lem']]\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 2. Création du modèle FastText sur l'ensemble du corpus\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    ft_model = FastText(\n",
    "        sentences=tokenized_tweets,\n",
    "        vector_size=params[\"vector_size\"],  \n",
    "        window=params[\"window\"],\n",
    "        min_count=params[\"min_count\"],\n",
    "        epochs=params[\"epochs\"],\n",
    "        workers=10\n",
    "    )\n",
    "    \n",
    "    # Sauvegarde du modèle FastText dans MLflow en tant qu'artifact\n",
    "    ft_model_path = \"fasttext.model\"\n",
    "    ft_model.save(ft_model_path)\n",
    "    mlflow.log_artifact(ft_model_path, artifact_path=\"FastText\")\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 3. Obtention des vecteurs pour chaque tweet\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "\n",
    "    def get_sentence_vector(sentence, model, dim):\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            return np.concatenate([np.mean(vectors, axis=0), np.max(vectors, axis=0), np.min(vectors, axis=0)])\n",
    "        else:\n",
    "            return np.zeros(dim * 3)\n",
    "    \n",
    "    X = np.array([get_sentence_vector(text, ft_model, params[\"vector_size\"]) for text in tokenized_tweets])\n",
    "    y = data['target'].reset_index(drop=True).values  # Convertir en array\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 4. Split en train/test (85/15)\n",
    "    #-------------------------------------------------\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    # 5. Construction du modèle CNN + BiLSTM\n",
    "    # -------------------------------------------------\n",
    "    \n",
    "    model = Sequential([\n",
    "        Input(shape=(params[\"vector_size\"], 1)),  # Format (timesteps, features)\n",
    "        Bidirectional(LSTM(128, dropout=0.1, recurrent_dropout=0.1)),  # BiLSTM \n",
    "        Dense(128, activation='relu'),     # Dense avec réduction des unités et un dropout plus bas\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    \n",
    "    model.compile(optimizer=TfAdam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Early Stopping & Model Checkpoint\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_loss', save_best_only=True, mode='min')\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 6. Entraînement du modèle & Prédiction\n",
    "    #-------------------------------------------------\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        validation_split=0.15,\n",
    "        callbacks=[early_stopping, checkpoint]\n",
    "    )\n",
    "    \n",
    "    # Chargement du meilleur modèle\n",
    "    model.load_weights(\"best_model.h5\")\n",
    "    \n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 7. Résultats \n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    cout_metier = fp + fn\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Matrice de confusion:\\n\", conf_matrix)\n",
    "    print(\"Coût métier:\", cout_metier)\n",
    "    \n",
    "    # Logs des résultats dans MLflow\n",
    "    mlflow.log_metric(\"Accuracy\", round(accuracy, 3))\n",
    "    mlflow.log_metric(\"F1_Score\", round(f1, 3))\n",
    "    mlflow.log_metric(\"Coût métier\", cout_metier)\n",
    "    mlflow.log_metric(\"FN\", fn)\n",
    "    mlflow.log_metric(\"FP\", fp)\n",
    "    \n",
    "    # Enregistrement du modèle LSTM dans MLflow\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "    mlflow.keras.log_model(model, \"LSTM_Model\", signature=signature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc9b31a-da29-41eb-bf78-853ecb7c2357",
   "metadata": {},
   "source": [
    "En conclusion, nous voyons que tous ces modèles, même si ils ne sont pas totalement optimisés, sont plus lents et donnent de bien moins bons résultats que notre baseline, une simple régression logistique...\n",
    "Passons maintenant à BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b82d99f-2264-430d-a922-1e0f62c526f1",
   "metadata": {},
   "source": [
    "## 5.3 BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c67eb6-e1e5-42af-85c0-81ff1ee8c159",
   "metadata": {},
   "source": [
    "BERT Hugging face:\n",
    "BERT (Bidirectional Encoder Representations from Transformers) est un modèle de langage pré-entraîné utilisant l'architecture Transformer. Contrairement aux modèles traditionnels, il est bidirectionnel, ce qui lui permet de mieux capturer le contexte des mots dans une phrase. BERT est particulièrement puissant pour des tâches de compréhension du langage comme la classification de texte, la réponse à des questions et l'extraction d'entités.\n",
    "On utilisera ici un tokenizer propre à BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c0698c-7eab-4c78-938d-9c77628d8602",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multiprocessing.cpu_count())  # Nombre total de cœurs logiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9c15f3-8d1c-4240-b9a8-a9ed99be818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(\"GPU disponible :\", tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5995b5fe-e1db-4423-9611-70ac5df2a95b",
   "metadata": {},
   "source": [
    "Voici les étapes principales du code ci-dessous:\n",
    "\n",
    "1. Initialisation du modèle et du tokenizer\n",
    "On charge DistilBERT ainsi que son tokenizer qui convertira le texte en données exploitables par le modèle.\n",
    "\n",
    "2. Paramètres d'entraînement\n",
    "On définit les réglages du modèle : nombre d'époques (combien de fois on passe sur les données), taille des lots de données traités en même temps, et le taux d'apprentissage (vitesse d'adaptation du modèle).\n",
    "\n",
    "3. Préparation des données, divisées en trois groupes :\n",
    "\n",
    "* 80% pour l'entraînement\n",
    "* 10% pour la validation (vérifier que le modèle ne s'entraîne pas trop sur un même schéma)\n",
    "* 10% pour le test final\n",
    "Ensuite, on transforme ces textes en tokens exploitables par le modèle.\n",
    "\n",
    "4. Création des datasets TensorFlow\n",
    "On met en forme les données pour qu'elles soient prêtes à être utilisées par TensorFlow, en les regroupant en lots et en optimisant leur chargement.\n",
    "\n",
    "5. Définition de l'optimiseur et compilation\n",
    "On choisit l'algorithme qui ajustera le modèle (AdamWeightDecay) et la fonction qui mesurera l'erreur (loss function).\n",
    "\n",
    "6. Entraînement du modèle\n",
    "Le modèle apprend en analysant les données d’entraînement et en ajustant ses paramètres. On vérifie la progression en regardant les performances sur le jeu de validation.\n",
    "\n",
    "7. Sauvegarde et log des résultats\n",
    "On sauvegarde le modèle et le tokenizer, et on enregistre les résultats dans MLflow pour pouvoir les analyser plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412b7cc5-96d6-4098-bf07-b927ccc37557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import mlflow\n",
    "# import mlflow.tensorflow\n",
    "# import tensorflow as tf\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "# from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "from transformers import AdamWeightDecay\n",
    "\n",
    "# XLA (Accelerated Linear Algebra) optimise les opérations TensorFlow en fusionnant plusieurs calculs.\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=2\"\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"1\"\n",
    "\n",
    "# Démarrage de la session MLflow\n",
    "with mlflow.start_run(run_name=\"DistilBERT_Model_Classification\"):\n",
    "    mlflow.set_tag(\"Approach\", \"DistilBERT\")\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 1. Initialisation du modèle et du tokenizer\n",
    "    #-------------------------------------------------\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = TFDistilBertForSequenceClassification.from_pretrained(\n",
    "        'distilbert-base-uncased', \n",
    "        num_labels=2, # classification binaire => num_labels=2\n",
    "        from_pt=True # Gain de temps : évite la conversion automatique PyTorch → TensorFlow.\n",
    "    )\n",
    "\n",
    "    #-------------------------------------------------\n",
    "    # 2. Paramètres d'entraînement\n",
    "    #-------------------------------------------------\n",
    "    params = {\n",
    "        \"epochs\": 3,  \n",
    "        \"batch_size\": 32,  \n",
    "        \"lr\": 2e-5,  \n",
    "    }\n",
    "\n",
    "    # Log des paramètres dans MLflow\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 3. Tokenisation et split des données (80% train, 10% validation, 10% test)\n",
    "    #-------------------------------------------------\n",
    "    X = [str(tweet) for tweet in data['sentence_BERT']]\n",
    "    y = data['target'].reset_index(drop=True)\n",
    "\n",
    "    #Double train_test_split pour definir un dataset de validation:\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "    # Tokenisation des ensembles\n",
    "    train_tokens = tokenizer(X_train, padding=True, truncation=True, return_tensors=\"tf\", max_length=64)  \n",
    "    val_tokens = tokenizer(X_val, padding=True, truncation=True, return_tensors=\"tf\", max_length=64)\n",
    "    test_tokens = tokenizer(X_test, padding=True, truncation=True, return_tensors=\"tf\", max_length=64)\n",
    "    \n",
    "    # Extraction des tenseurs\n",
    "    train_input_ids = train_tokens['input_ids']\n",
    "    train_attention_mask = train_tokens['attention_mask']\n",
    "    val_input_ids = val_tokens['input_ids']\n",
    "    val_attention_mask = val_tokens['attention_mask']\n",
    "    test_input_ids = test_tokens['input_ids']\n",
    "    test_attention_mask = test_tokens['attention_mask']\n",
    "\n",
    "    # Conversion des labels\n",
    "    y_train = tf.convert_to_tensor(y_train.values, dtype=tf.int32)\n",
    "    y_val = tf.convert_to_tensor(y_val.values, dtype=tf.int32)\n",
    "    y_test = tf.convert_to_tensor(y_test.values, dtype=tf.int32)\n",
    "    \n",
    "\n",
    "\n",
    "    #-------------------------------------------------\n",
    "    # 4. Création des datasets TensorFlow\n",
    "    #-------------------------------------------------\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        ({\"input_ids\": train_input_ids, \"attention_mask\": train_attention_mask}, y_train)\n",
    "    ).shuffle(len(y_train)).batch(params[\"batch_size\"]).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        ({\"input_ids\": val_input_ids, \"attention_mask\": val_attention_mask}, y_val)\n",
    "    ).batch(params[\"batch_size\"]).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        ({\"input_ids\": test_input_ids, \"attention_mask\": test_attention_mask}, y_test)\n",
    "    ).batch(params[\"batch_size\"]).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    #-------------------------------------------------\n",
    "    # 5. Définition de l'optimiseur et compilation\n",
    "    #-------------------------------------------------\n",
    "    optimizer = AdamWeightDecay(learning_rate=params[\"lr\"])\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_path = \"best_distilbert_model\"\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # 6. Entraînement du modèle\n",
    "    #-------------------------------------------------\n",
    "    full_history = {\n",
    "        \"loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"accuracy\": [],\n",
    "        \"val_accuracy\": []\n",
    "    }\n",
    "\n",
    "    \n",
    "    for epoch in range(params[\"epochs\"]):\n",
    "        history = model.fit(train_dataset, validation_data=validation_dataset, epochs=1, verbose=1)\n",
    "\n",
    "        # Stockage des valeurs dans full_history\n",
    "        full_history[\"loss\"].append(history.history[\"loss\"][0])\n",
    "        full_history[\"val_loss\"].append(history.history[\"val_loss\"][0])\n",
    "        full_history[\"accuracy\"].append(history.history[\"accuracy\"][0])\n",
    "        full_history[\"val_accuracy\"].append(history.history[\"val_accuracy\"][0])\n",
    "    \n",
    "        val_loss = history.history[\"val_loss\"][0]\n",
    "        \n",
    "    #-------------------------------------------------\n",
    "    # 7. Log du tokenizer et du meilleur modele dans MLflow\n",
    "    #-------------------------------------------------\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "\n",
    "            model.save(\"best_distilbert_saved_model\", save_format=\"tf\")  # Sauvegarde en format TensorFlow SavedModel\n",
    "            tokenizer.save_pretrained(\"best_distilbert_tokenizer\")  # Sauvegarde du tokenizer\n",
    "            \n",
    "            # Loguer le modèle SavedModel dans MLflow\n",
    "            mlflow.tensorflow.log_model(model, \"model\")\n",
    "            \n",
    "            # Loguer le tokenizer comme fichier séparé dans MLflow\n",
    "            mlflow.log_artifact(\"best_distilbert_tokenizer\")  # Si nécessaire, sauvegarde le tokenizer aussi\n",
    "            \n",
    "    #-------------------------------------------------\n",
    "    # 8. Évaluation du modèle sur test set\n",
    "    #-------------------------------------------------\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for batch in test_dataset:\n",
    "        inputs, labels = batch\n",
    "        logits = model(inputs, training=False).logits\n",
    "        predictions = tf.argmax(logits, axis=-1)\n",
    "\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predictions.numpy())\n",
    "\n",
    "    #-------------------------------------------------\n",
    "    # 9. Résultats\n",
    "    #-------------------------------------------------\n",
    "\n",
    "    show_history(full_history)  \n",
    "    plot_history(full_history, path=f\"training_history.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    cout_metier = fp + fn\n",
    "\n",
    "    print(\"Accuracy:\", round(accuracy, 3))\n",
    "    print(\"F1 Score:\", round(f1, 3))\n",
    "    print(\"Matrice de confusion:\\n\", conf_matrix)\n",
    "    print(\"Coût métier:\", cout_metier)\n",
    "\n",
    "    # Log des résultats dans MLflow\n",
    "    mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"F1_Score\", f1)\n",
    "    mlflow.log_metric(\"Coût métier\", cout_metier)\n",
    "    mlflow.log_metric(\"FN\", fn)\n",
    "    mlflow.log_metric(\"FP\", fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d0c17-21aa-4ce0-9a04-2881ad329919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verification des data train vs test:\n",
    "print(\"Train class distribution:\", np.bincount(y_train))\n",
    "print(\"Test class distribution:\", np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4116678-9a3e-45c8-b1eb-192787ccf6a7",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c595bd-abfd-4db7-8e00-0a22801d5a0a",
   "metadata": {},
   "source": [
    "De tous les modèles testés, BERT est clariement le plus performant; c'est donc celui ci que l'on utilisera pour le déploiement en production sur Azure Web Services."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
